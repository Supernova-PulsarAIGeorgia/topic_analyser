{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"55b5a3c6f52d4ac19853013dfddc74be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b64d9aa8f1b4333b3fee4f97cfb4925","IPY_MODEL_be3a8727261f4d368804469b3b79b235","IPY_MODEL_b17972d094b2439c97271591726ccdea"],"layout":"IPY_MODEL_4b374d77515f498e98a22b4245429af6"}},"6b64d9aa8f1b4333b3fee4f97cfb4925":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8aa4d69cc71437ea6235efbf94c068e","placeholder":"​","style":"IPY_MODEL_f3ea63bfdf0b4ec5a1b51eb35e10def2","value":"Stringifying the column: 100%"}},"be3a8727261f4d368804469b3b79b235":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dfc5dd0c9da4ab98a3ebaa9da49a3f4","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2383d63d6b3d46f88b6981a2590e6d4d","value":8}},"b17972d094b2439c97271591726ccdea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f7db0b74ce64092a7a97b97a2f35855","placeholder":"​","style":"IPY_MODEL_b89cfb8f10cd45a1a2e6e165eb2720f9","value":" 8/8 [00:00&lt;00:00, 118.44ba/s]"}},"4b374d77515f498e98a22b4245429af6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8aa4d69cc71437ea6235efbf94c068e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3ea63bfdf0b4ec5a1b51eb35e10def2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7dfc5dd0c9da4ab98a3ebaa9da49a3f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2383d63d6b3d46f88b6981a2590e6d4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f7db0b74ce64092a7a97b97a2f35855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b89cfb8f10cd45a1a2e6e165eb2720f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"555e4e2dcba94921a41742e96a2076e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86b21bb801b649c2bd38716cd9720f47","IPY_MODEL_87c899796041463e854322aeb2fbac48","IPY_MODEL_3d2d991bce05408187d84318369c5ab4"],"layout":"IPY_MODEL_73c494bb43984a4482896a9d8d448703"}},"86b21bb801b649c2bd38716cd9720f47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_602d09f5b9574bf9adc24aa4dab31d91","placeholder":"​","style":"IPY_MODEL_caa02d04972142359d25c8481b34734b","value":"Casting to class labels: 100%"}},"87c899796041463e854322aeb2fbac48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d814269dd4674f0093e8b91c59cd9def","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e2256f0b63142e49760c76be488096f","value":8}},"3d2d991bce05408187d84318369c5ab4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b2d88b5cb3d40589f185c2b38468886","placeholder":"​","style":"IPY_MODEL_18fa29dfd7804523b92f8151243a7898","value":" 8/8 [00:00&lt;00:00, 114.26ba/s]"}},"73c494bb43984a4482896a9d8d448703":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"602d09f5b9574bf9adc24aa4dab31d91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caa02d04972142359d25c8481b34734b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d814269dd4674f0093e8b91c59cd9def":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e2256f0b63142e49760c76be488096f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b2d88b5cb3d40589f185c2b38468886":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18fa29dfd7804523b92f8151243a7898":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5341417071f4350b8d682832ced46e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ba24ee73fc843b2bfc1e75d32bd03f3","IPY_MODEL_dd845f6e3a7441a8b689f779c547829e","IPY_MODEL_d79cab2db587435cb7c6e02496a9d8c0"],"layout":"IPY_MODEL_e4e8d9eb93c241348d82db2056982d24"}},"6ba24ee73fc843b2bfc1e75d32bd03f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f54a83da7b49499585084df6300e3c4b","placeholder":"​","style":"IPY_MODEL_741b88ae34ef4eb18993f5b625982c52","value":"Casting the dataset: 100%"}},"dd845f6e3a7441a8b689f779c547829e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c10ec2cf967341508bbcf6368a27e337","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a16d6729f5214a73aa2f2ebca2d26335","value":1}},"d79cab2db587435cb7c6e02496a9d8c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08e56d35a4144f928e8f22feed67395e","placeholder":"​","style":"IPY_MODEL_e9a5f66c9eef4731aaaea8f25ec7fe77","value":" 1/1 [00:00&lt;00:00, 19.50ba/s]"}},"e4e8d9eb93c241348d82db2056982d24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f54a83da7b49499585084df6300e3c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"741b88ae34ef4eb18993f5b625982c52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c10ec2cf967341508bbcf6368a27e337":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a16d6729f5214a73aa2f2ebca2d26335":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08e56d35a4144f928e8f22feed67395e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9a5f66c9eef4731aaaea8f25ec7fe77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e181f40fffa42f998669ca89d537126":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_310aeff5de37459a9278868a2947e417","IPY_MODEL_6cffd2aaab8647ba88f305c94cf060c4","IPY_MODEL_1d4e626a614d4399998a24d00a972372"],"layout":"IPY_MODEL_6f935b859340443697718419fc72ce74"}},"310aeff5de37459a9278868a2947e417":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da71ebfa06c24ff2a5e08e07be351a93","placeholder":"​","style":"IPY_MODEL_052280b7aec24fd1a75d896e82b84b4b","value":"100%"}},"6cffd2aaab8647ba88f305c94cf060c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cf98361b30747d1a94f826d47bbf11a","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4578ba9df8a426fa81d3c5713f7f282","value":7}},"1d4e626a614d4399998a24d00a972372":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a02a28e415ec462eacbe1a8981e92d70","placeholder":"​","style":"IPY_MODEL_157844d90ed345ecac7537a724365bd4","value":" 7/7 [00:01&lt;00:00,  5.11ba/s]"}},"6f935b859340443697718419fc72ce74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da71ebfa06c24ff2a5e08e07be351a93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"052280b7aec24fd1a75d896e82b84b4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cf98361b30747d1a94f826d47bbf11a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4578ba9df8a426fa81d3c5713f7f282":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a02a28e415ec462eacbe1a8981e92d70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"157844d90ed345ecac7537a724365bd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75df942d87c84d0f8ad9b5c7e05fd50c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a63df24fc9354912adbd0cc63146994a","IPY_MODEL_eb1b1a9f5e1949478cdcaebb9647ba65","IPY_MODEL_c2ff682245f24ad9b6fc3e582a071516"],"layout":"IPY_MODEL_33cc8e1b95674dc6b4dddf4c4ed88bd1"}},"a63df24fc9354912adbd0cc63146994a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab6195dde47543bebff0a8498101d712","placeholder":"​","style":"IPY_MODEL_baabe02abef7432d8038a2f88ff555b2","value":"100%"}},"eb1b1a9f5e1949478cdcaebb9647ba65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_322a6b5461304e2faf34a299cd57f280","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39a471b3a3e64334b03e96961c4c7efa","value":1}},"c2ff682245f24ad9b6fc3e582a071516":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3c92f1ebdcb4dc08e31ca6080909117","placeholder":"​","style":"IPY_MODEL_e702a444917247929af2e146830d3bb6","value":" 1/1 [00:00&lt;00:00,  4.07ba/s]"}},"33cc8e1b95674dc6b4dddf4c4ed88bd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab6195dde47543bebff0a8498101d712":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baabe02abef7432d8038a2f88ff555b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"322a6b5461304e2faf34a299cd57f280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39a471b3a3e64334b03e96961c4c7efa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3c92f1ebdcb4dc08e31ca6080909117":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e702a444917247929af2e146830d3bb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3db16fb70f0a4acb9ddf478b0cfa46ad":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_eea8d7afd8494f91ab0159686299cc0b","IPY_MODEL_6dfd82ee28404cfbb230af060103f244"],"layout":"IPY_MODEL_2e71fe3087b444469fe9e7e49bcf3d50"}},"eea8d7afd8494f91ab0159686299cc0b":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bc89c297e50422486d2e983c532eba1","placeholder":"​","style":"IPY_MODEL_43fc74101399406597941c6dc2999f45","value":"0.484 MB of 0.484 MB uploaded (0.000 MB deduped)\r"}},"6dfd82ee28404cfbb230af060103f244":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cae7001edb2474da06d6bb4b45891f7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5312a7318e7442a8638003bdab1a1d7","value":1}},"2e71fe3087b444469fe9e7e49bcf3d50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bc89c297e50422486d2e983c532eba1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43fc74101399406597941c6dc2999f45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cae7001edb2474da06d6bb4b45891f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5312a7318e7442a8638003bdab1a1d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}},"gpuClass":"standard"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c_k4p4K7kIKR","executionInfo":{"status":"ok","timestamp":1662452812981,"user_tz":-240,"elapsed":2414,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"a0f1d6bc-44a3-4707-d688-e2c0918e769e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"OMqC5Uw2gaka","executionInfo":{"status":"ok","timestamp":1662452814747,"user_tz":-240,"elapsed":268,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOsHUjgdIrIW","executionInfo":{"status":"ok","timestamp":1662452821125,"user_tz":-240,"elapsed":4235,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"3bee4225-9e1d-4b0a-fcdc-ddf1f51c7450"},"source":["! pip install datasets transformers sentencepiece"],"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCOM583qcEp5","executionInfo":{"status":"ok","timestamp":1662452825522,"user_tz":-240,"elapsed":378,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"09a0b0de-96d9-4fc9-c7aa-fc779f039cf1"},"source":["import transformers\n","print(transformers.__version__)\n","\n","import pickle"],"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["4.21.3\n"]}]},{"cell_type":"code","metadata":{"id":"A-Tleulzkmo-","executionInfo":{"status":"ok","timestamp":1662452828589,"user_tz":-240,"elapsed":291,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["task_path = '/content/drive/My Drive/Supernova-NLP/intent classification/intent classification'\n","max_length = 128"],"execution_count":74,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"whPRbBNbIrIl"},"source":["## Loading the dataset"]},{"cell_type":"code","metadata":{"id":"IreSlFmlIrIm","executionInfo":{"status":"ok","timestamp":1662452831003,"user_tz":-240,"elapsed":354,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["import datasets\n","from datasets import load_metric\n","from datasets import DatasetDict, Dataset, ClassLabel\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":75,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DYGlTdwPQ3Ym"},"source":["[link text](https://)Read sentences from excel"]},{"cell_type":"code","metadata":{"id":"YxTYPUYBj7No","executionInfo":{"status":"ok","timestamp":1662452835078,"user_tz":-240,"elapsed":1350,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["df_sentences = pd.read_excel(f'{task_path}/topic-data.xlsx')[[\"INTENT\", \"SENTENCES\"]]\n","df_sentences = df_sentences.loc[pd.notnull(df_sentences['INTENT'])]"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"ICuqWAGpkdda","executionInfo":{"elapsed":408,"status":"ok","timestamp":1662452837930,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"},"user_tz":-240},"outputId":"080372a4-6fd0-4cde-b131-739c369ca3e4"},"source":["fig = plt.figure()\n","ax = fig.subplots()\n","ax.hist(df_sentences['INTENT'])\n","plt.show()"],"execution_count":77,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"qdPFCSMyRs4i"},"source":["Make datasets.Dataset object and split into two sets"]},{"cell_type":"code","metadata":{"id":"MIgX7FRYs1CI","executionInfo":{"status":"ok","timestamp":1662452841002,"user_tz":-240,"elapsed":257,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["classes = list(pd.unique(df_sentences['INTENT']))\n","classLabel = ClassLabel(num_classes=len(classes), names=classes)"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvpOPwsQkeLU","executionInfo":{"status":"ok","timestamp":1662452844539,"user_tz":-240,"elapsed":276,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["with open(f'{task_path}/models/classLabel.pickle', 'wb') as handle:\n","    pickle.dump(classLabel, handle)"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSZZvXivj8Er","executionInfo":{"status":"ok","timestamp":1662452847469,"user_tz":-240,"elapsed":266,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["dataset = Dataset.from_dict({'sentence':df_sentences['SENTENCES'], 'label':classLabel.str2int(df_sentences['INTENT']), 'idx':df_sentences.index})"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["55b5a3c6f52d4ac19853013dfddc74be","6b64d9aa8f1b4333b3fee4f97cfb4925","be3a8727261f4d368804469b3b79b235","b17972d094b2439c97271591726ccdea","4b374d77515f498e98a22b4245429af6","d8aa4d69cc71437ea6235efbf94c068e","f3ea63bfdf0b4ec5a1b51eb35e10def2","7dfc5dd0c9da4ab98a3ebaa9da49a3f4","2383d63d6b3d46f88b6981a2590e6d4d","7f7db0b74ce64092a7a97b97a2f35855","b89cfb8f10cd45a1a2e6e165eb2720f9","555e4e2dcba94921a41742e96a2076e1","86b21bb801b649c2bd38716cd9720f47","87c899796041463e854322aeb2fbac48","3d2d991bce05408187d84318369c5ab4","73c494bb43984a4482896a9d8d448703","602d09f5b9574bf9adc24aa4dab31d91","caa02d04972142359d25c8481b34734b","d814269dd4674f0093e8b91c59cd9def","2e2256f0b63142e49760c76be488096f","6b2d88b5cb3d40589f185c2b38468886","18fa29dfd7804523b92f8151243a7898","d5341417071f4350b8d682832ced46e8","6ba24ee73fc843b2bfc1e75d32bd03f3","dd845f6e3a7441a8b689f779c547829e","d79cab2db587435cb7c6e02496a9d8c0","e4e8d9eb93c241348d82db2056982d24","f54a83da7b49499585084df6300e3c4b","741b88ae34ef4eb18993f5b625982c52","c10ec2cf967341508bbcf6368a27e337","a16d6729f5214a73aa2f2ebca2d26335","08e56d35a4144f928e8f22feed67395e","e9a5f66c9eef4731aaaea8f25ec7fe77"]},"id":"RMwlUQU_IXTe","executionInfo":{"elapsed":806,"status":"ok","timestamp":1662452849878,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"},"user_tz":-240},"outputId":"3e52d5a3-9e39-493f-d5ab-99abf8ac806f"},"source":["dataset = dataset.class_encode_column('label')"],"execution_count":81,"outputs":[{"output_type":"display_data","data":{"text/plain":["Stringifying the column:   0%|          | 0/8 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55b5a3c6f52d4ac19853013dfddc74be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Casting to class labels:   0%|          | 0/8 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"555e4e2dcba94921a41742e96a2076e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5341417071f4350b8d682832ced46e8"}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"T1AynHApA1Ht","executionInfo":{"status":"ok","timestamp":1662452854862,"user_tz":-240,"elapsed":281,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["train_size = 0.9\n","dataset = dataset.train_test_split(train_size=train_size)"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eYDNCX9vcpUI","executionInfo":{"elapsed":268,"status":"ok","timestamp":1662452860887,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"},"user_tz":-240},"outputId":"73e2a7b8-0048-4479-f8c9-144a3e2b1cf4"},"source":["dataset['train'], dataset['test']"],"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(Dataset({\n","     features: ['sentence', 'label', 'idx'],\n","     num_rows: 6632\n"," }), Dataset({\n","     features: ['sentence', 'label', 'idx'],\n","     num_rows: 737\n"," }))"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["dataset['test'][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uwev5Hotjte1","executionInfo":{"status":"ok","timestamp":1662452868202,"user_tz":-240,"elapsed":252,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"53a0a895-6509-47da-e272-2f13a1ae642d"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'sentence': 'ვინ შეასრულებს თერთმეტმეტრიანებს \"კვარა\" თუ ოსიმენი? - ნეაპოლური გამოცემის ვრცელი ანალიზი',\n"," 'label': 1,\n"," 'idx': 3539}"]},"metadata":{},"execution_count":84}]},{"cell_type":"markdown","metadata":{"id":"lnjDIuQ3IrI-"},"source":["Load Metric. The metric is an instance of [`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric):"]},{"cell_type":"code","metadata":{"id":"7KRV6XpwuiDS","executionInfo":{"status":"ok","timestamp":1662452871696,"user_tz":-240,"elapsed":712,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["metric = load_metric(\"accuracy\")"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5o4rUteaIrI_","executionInfo":{"elapsed":589,"status":"ok","timestamp":1662452875301,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"},"user_tz":-240},"outputId":"033c0677-549c-465c-f8b7-46ca4f2b5be5"},"source":["metric"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Metric(name: \"accuracy\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n","Args:\n","    predictions (`list` of `int`): Predicted labels.\n","    references (`list` of `int`): Ground truth labels.\n","    normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.\n","    sample_weight (`list` of `float`): Sample weights Defaults to None.\n","\n","Returns:\n","    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.\n","\n","Examples:\n","\n","    Example 1-A simple example\n","        >>> accuracy_metric = datasets.load_metric(\"accuracy\")\n","        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])\n","        >>> print(results)\n","        {'accuracy': 0.5}\n","\n","    Example 2-The same as Example 1, except with `normalize` set to `False`.\n","        >>> accuracy_metric = datasets.load_metric(\"accuracy\")\n","        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)\n","        >>> print(results)\n","        {'accuracy': 3.0}\n","\n","    Example 3-The same as Example 1, except with `sample_weight` set.\n","        >>> accuracy_metric = datasets.load_metric(\"accuracy\")\n","        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])\n","        >>> print(results)\n","        {'accuracy': 0.8778625954198473}\n","\"\"\", stored examples: 0)"]},"metadata":{},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"n9qywopnIrJH"},"source":["## Preprocessing the data"]},{"cell_type":"markdown","metadata":{"id":"-OH3j00VSBJX"},"source":["Import tokenizer for XLM-Roberta"]},{"cell_type":"code","metadata":{"id":"wu_r0moA7GY-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662452883973,"user_tz":-240,"elapsed":1280,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"20b96cd8-3519-455b-97b1-789c8f1d496f"},"source":["from transformers import XLMRobertaTokenizer\n","\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')#, use_fast=True)"],"execution_count":87,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n","loading file https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.21.3\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"rowT4iCLIrJK"},"source":["You can directly call this tokenizer on one sentence or a pair of sentences:"]},{"cell_type":"code","metadata":{"id":"a5hBlsrHIrJL"},"source":["#tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\", truncation=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XbP_PdFSSLhi"},"source":["Do all preproccessing with this function."]},{"cell_type":"code","metadata":{"id":"QQTwJ-PDRf1M","executionInfo":{"status":"ok","timestamp":1662452890878,"user_tz":-240,"elapsed":254,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["def preprocess_function(examples):\n","    # All sentences will be padded ot truncated to max_length\n","    return tokenizer(examples['sentence'], padding='max_length', truncation=True, max_length=max_length)"],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["4e181f40fffa42f998669ca89d537126","310aeff5de37459a9278868a2947e417","6cffd2aaab8647ba88f305c94cf060c4","1d4e626a614d4399998a24d00a972372","6f935b859340443697718419fc72ce74","da71ebfa06c24ff2a5e08e07be351a93","052280b7aec24fd1a75d896e82b84b4b","4cf98361b30747d1a94f826d47bbf11a","f4578ba9df8a426fa81d3c5713f7f282","a02a28e415ec462eacbe1a8981e92d70","157844d90ed345ecac7537a724365bd4","75df942d87c84d0f8ad9b5c7e05fd50c","a63df24fc9354912adbd0cc63146994a","eb1b1a9f5e1949478cdcaebb9647ba65","c2ff682245f24ad9b6fc3e582a071516","33cc8e1b95674dc6b4dddf4c4ed88bd1","ab6195dde47543bebff0a8498101d712","baabe02abef7432d8038a2f88ff555b2","322a6b5461304e2faf34a299cd57f280","39a471b3a3e64334b03e96961c4c7efa","a3c92f1ebdcb4dc08e31ca6080909117","e702a444917247929af2e146830d3bb6"]},"id":"DDtsaJeVIrJT","executionInfo":{"elapsed":2022,"status":"ok","timestamp":1662452894536,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"},"user_tz":-240},"outputId":"9153edcc-76d0-4449-e087-c484bd81822d"},"source":["encoded_dataset = dataset.map(preprocess_function, batched=True, load_from_cache_file=False)"],"execution_count":89,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e181f40fffa42f998669ca89d537126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75df942d87c84d0f8ad9b5c7e05fd50c"}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"RKZXGT-ym970","executionInfo":{"status":"ok","timestamp":1662452898629,"user_tz":-240,"elapsed":283,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["encoded_dataset.set_format(type = 'torch', device=device)"],"execution_count":90,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"545PP3o8IrJV"},"source":["## Fine-tuning the model"]},{"cell_type":"markdown","metadata":{"id":"CovxAjpJS2eG"},"source":["Import Model and Trainer"]},{"cell_type":"code","metadata":{"id":"TlqNaB8jIrJW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662452901892,"user_tz":-240,"elapsed":424,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"101609f0-cc97-4f8c-d128-e142eb55e0e3"},"source":["from transformers import TrainingArguments, Trainer\n","from transformers import XLMRobertaForSequenceClassification, XLMRobertaConfig\n","\n","config = XLMRobertaConfig.from_pretrained('xlm-roberta-base')\n","config.num_labels = classLabel.num_classes"],"execution_count":91,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n","Model config XLMRobertaConfig {\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.21.3\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Srx1-OFDtbdx","executionInfo":{"elapsed":6452,"status":"ok","timestamp":1662452914320,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"},"user_tz":-240},"outputId":"7dfe5bf8-9d34-4033-a81f-f72cf4847e76"},"source":["model = XLMRobertaForSequenceClassification(config)\n","model.to(device)"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGORUEd3pvRu","executionInfo":{"elapsed":3567,"status":"ok","timestamp":1662452924186,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"},"user_tz":-240},"outputId":"3df79146-0a2c-4f30-f9a4-b2699389b509"},"source":["! pip install wandb"],"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.2)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khUJlK2yppQc","executionInfo":{"elapsed":305,"status":"ok","timestamp":1662452928767,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"},"user_tz":-240},"outputId":"e786b738-283b-4a5f-9ba1-e272a760f73d"},"source":["import wandb\n","wandb.login()"],"execution_count":94,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","metadata":{"id":"Bliy8zgjIrJY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662452933724,"user_tz":-240,"elapsed":478,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"fe7c4564-05c1-4e77-8172-f357980d4f6d"},"source":["metric_name = \"accuracy\"\n","batch_size = 16\n","\n","args = TrainingArguments(\n","    f\"{task_path}/models\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=8,\n","    weight_decay=0.05,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metric_name,\n","    report_to='wandb'\n",")"],"execution_count":95,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n"]}]},{"cell_type":"code","metadata":{"id":"UmvbnJ9JIrJd","executionInfo":{"status":"ok","timestamp":1662452937142,"user_tz":-240,"elapsed":269,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["import numpy as np\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return metric.compute(predictions=predictions, references=labels)"],"execution_count":96,"outputs":[]},{"cell_type":"code","metadata":{"id":"imY1oC3SIrJf","executionInfo":{"status":"ok","timestamp":1662452939291,"user_tz":-240,"elapsed":281,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=encoded_dataset[\"train\"],\n","    eval_dataset=encoded_dataset['test'],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"execution_count":97,"outputs":[]},{"cell_type":"code","source":["!wandb login --relogin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLTrTTyMZJCz","executionInfo":{"status":"ok","timestamp":1662373796748,"user_tz":-240,"elapsed":14973,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"02589dff-ef47-418c-8f15-5fdacb3e0d02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484,"referenced_widgets":["3db16fb70f0a4acb9ddf478b0cfa46ad","eea8d7afd8494f91ab0159686299cc0b","6dfd82ee28404cfbb230af060103f244","2e71fe3087b444469fe9e7e49bcf3d50","5bc89c297e50422486d2e983c532eba1","43fc74101399406597941c6dc2999f45","9cae7001edb2474da06d6bb4b45891f7","e5312a7318e7442a8638003bdab1a1d7"]},"id":"l2dwvB6do0yB","executionInfo":{"elapsed":7412,"status":"ok","timestamp":1662452950222,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"},"user_tz":-240},"outputId":"2858d75e-e049-4e23-b3cc-f65140984af4"},"source":["wandb.init(project=\"intent-classification\", entity=\"orkhanshamil\")"],"execution_count":98,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:2zzxrpxy) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3db16fb70f0a4acb9ddf478b0cfa46ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▆█▇</td></tr><tr><td>eval/loss</td><td>▇▅▃▁█</td></tr><tr><td>eval/runtime</td><td>█▂▄▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▅██</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▅██</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▅▆▇█</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▅▆▇█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.83469</td></tr><tr><td>eval/loss</td><td>0.67627</td></tr><tr><td>eval/runtime</td><td>1.6319</td></tr><tr><td>eval/samples_per_second</td><td>226.122</td></tr><tr><td>eval/steps_per_second</td><td>14.707</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>2190</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.2587</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">robust-snowflake-3</strong>: <a href=\"https://wandb.ai/orkhanshamil/intent-classification/runs/2zzxrpxy\" target=\"_blank\">https://wandb.ai/orkhanshamil/intent-classification/runs/2zzxrpxy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220906_081434-2zzxrpxy/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:2zzxrpxy). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220906_082902-390w43p0</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/orkhanshamil/intent-classification/runs/390w43p0\" target=\"_blank\">faithful-snowball-4</a></strong> to <a href=\"https://wandb.ai/orkhanshamil/intent-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/orkhanshamil/intent-classification/runs/390w43p0?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f4f90a2e150>"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"uNx5pyRlIrJh","outputId":"37d633f2-c455-43f1-cfb2-c355988bf016","executionInfo":{"status":"ok","timestamp":1662453943731,"user_tz":-240,"elapsed":988116,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["trainer.train()"],"execution_count":99,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 6632\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3320\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3320' max='3320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3320/3320 16:27, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.582800</td>\n","      <td>0.784261</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.849300</td>\n","      <td>0.562292</td>\n","      <td>0.805970</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.451400</td>\n","      <td>0.499047</td>\n","      <td>0.820896</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.328300</td>\n","      <td>0.481011</td>\n","      <td>0.852103</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.232600</td>\n","      <td>0.463823</td>\n","      <td>0.877883</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.232600</td>\n","      <td>0.554773</td>\n","      <td>0.869742</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.172000</td>\n","      <td>0.597392</td>\n","      <td>0.865672</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.136700</td>\n","      <td>0.647923</td>\n","      <td>0.862958</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 737\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-415\n","Configuration saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-415/config.json\n","Model weights saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-415/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-415/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-415/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 737\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-830\n","Configuration saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-830/config.json\n","Model weights saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-830/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-830/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-830/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 737\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1245\n","Configuration saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1245/config.json\n","Model weights saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1245/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1245/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1245/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 737\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1660\n","Configuration saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1660/config.json\n","Model weights saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1660/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1660/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-1660/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 737\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2075\n","Configuration saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2075/config.json\n","Model weights saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2075/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2075/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2075/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 737\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2490\n","Configuration saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2490/config.json\n","Model weights saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2490/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2490/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2490/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 737\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2905\n","Configuration saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2905/config.json\n","Model weights saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2905/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2905/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2905/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 737\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-3320\n","Configuration saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-3320/config.json\n","Model weights saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-3320/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-3320/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-3320/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/models/checkpoint-2075 (score: 0.8778833107191316).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3320, training_loss=0.3368153664002936, metrics={'train_runtime': 987.6167, 'train_samples_per_second': 53.721, 'train_steps_per_second': 3.362, 'total_flos': 3489967707193344.0, 'train_loss': 0.3368153664002936, 'epoch': 8.0})"]},"metadata":{},"execution_count":99}]},{"cell_type":"markdown","metadata":{"id":"CKASz-2vIrJi"},"source":["We can check with the `evaluate` method that our `Trainer` did reload the best model properly (if it was not the last one):"]},{"cell_type":"code","metadata":{"id":"UOUcBkX8IrJi","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"ok","timestamp":1662453961767,"user_tz":-240,"elapsed":3323,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"2c828cbd-76a7-4dd6-a97b-2d1f252c1b59"},"source":["trainer.evaluate()"],"execution_count":100,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 737\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [47/47 00:03]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.46382346749305725,\n"," 'eval_accuracy': 0.8778833107191316,\n"," 'eval_runtime': 3.2549,\n"," 'eval_samples_per_second': 226.426,\n"," 'eval_steps_per_second': 14.44,\n"," 'epoch': 8.0}"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"nWGUpPnZBGBr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662454187431,"user_tz":-240,"elapsed":4372,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"416bba18-be4f-4786-e352-a0641656dd51"},"source":[" trainer.save_model(task_path)"],"execution_count":102,"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/My Drive/Supernova-NLP/intent classification/intent classification\n","Configuration saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/config.json\n","Model weights saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/special_tokens_map.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"7k8ge1L1IrJk"},"source":["## Hyperparameter search"]},{"cell_type":"markdown","metadata":{"id":"RNfajuw_IrJl"},"source":["The `Trainer` supports hyperparameter search using [optuna](https://optuna.org/) or [Ray Tune](https://docs.ray.io/en/latest/tune/). For this last section you will need either of those libraries installed, just uncomment the line you want on the next cell and run it."]},{"cell_type":"code","metadata":{"id":"YUdakNBhIrJl"},"source":["#@title\n","# ! pip install optuna\n","# ! pip install ray[tune]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ttfT0CqaIrJm"},"source":["During hyperparameter search, the `Trainer` will run several trainings, so it needs to have the model defined via a function (so it can be reinitialized at each new run) instead of just having it passed. We jsut use the same function as before:"]},{"cell_type":"code","metadata":{"id":"8sgjdLKcIrJm"},"source":["#@title\n","def model_init():\n","    config = XLMRobertaConfig.from_pretrained('xlm-roberta-base')\n","    config.num_labels = classLabel.num_classes\n","    return XLMRobertaForSequenceClassification(config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mMXfVJO4IrJo"},"source":["And we can instantiate our `Trainer` like before:"]},{"cell_type":"code","metadata":{"id":"71pt6N0eIrJo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662378313086,"user_tz":-240,"elapsed":6263,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"d73edfdb-19dd-473b-9470-5d634cf904e2"},"source":["#@title\n","trainer = Trainer(\n","    model_init=model_init,\n","    args=args,\n","    train_dataset=encoded_dataset[\"train\"].shard(index=1, num_shards=5) ,\n","    eval_dataset=encoded_dataset['test'],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n","Model config XLMRobertaConfig {\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.21.3\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"yQxrzFP4IrJq"},"source":["The method we call this time is `hyperparameter_search`. Note that it can take a long time to run on the full dataset for some of the tasks. You can try to find some good hyperparameter on a portion of the training dataset by replacing the `train_dataset` line above by:\n","```python\n","train_dataset = encoded_dataset[\"train\"].shard(index=1, num_shards=10) \n","```\n","for 1/10th of the dataset. Then you can run a full training on the best hyperparameters picked by the search."]},{"cell_type":"code","metadata":{"id":"NboJ7kDOIrJq"},"source":["#@title\n","best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gUTD72qCIrJs"},"source":["The `hyperparameter_search` method returns a `BestRun` objects, which contains the value of the objective maximized (by default the sum of all metrics) and the hyperparameters it used for that run."]},{"cell_type":"code","metadata":{"id":"Psi4JymeIrJs"},"source":["#@title\n","best_run"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dFdjWbRIIrJu"},"source":["You can customize the objective to maximize by passing along a `compute_objective` function to the `hyperparameter_search` method, and you can customize the search space by passing a `hp_space` argument to `hyperparameter_search`. See this [forum post](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10) for some examples.\n","\n","To reproduce the best training, just set the hyperparameters in your `TrainingArgument` before creating a `Trainer`:"]},{"cell_type":"code","metadata":{"id":"EsJ6sqdGIrJu"},"source":["#@title\n","for n, v in best_run.hyperparameters.items():\n","    setattr(trainer.args, n, v)\n","\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vCMDT4kU4yg1"},"source":["# Demo"]},{"cell_type":"code","metadata":{"id":"aHcD4wKncEqI","executionInfo":{"status":"ok","timestamp":1662454274209,"user_tz":-240,"elapsed":532,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer"],"execution_count":103,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wzWT6DT5raIX"},"source":["Load model, tokenizer and label mapping"]},{"cell_type":"code","metadata":{"id":"GVfoI8bI9338","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662454304503,"user_tz":-240,"elapsed":4420,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"4742c190-7d5e-4f5b-b831-b7feaf465149"},"source":["model_folder = f'{task_path}'\n","model = XLMRobertaForSequenceClassification.from_pretrained(model_folder)\n","tokenizer = XLMRobertaTokenizer.from_pretrained(model_folder)\n","with open(f'{task_path}/models/classLabel.pickle', 'rb') as handle:\n","    classLabel = pickle.load(handle)"],"execution_count":104,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/config.json\n","Model config XLMRobertaConfig {\n","  \"architectures\": [\n","    \"XLMRobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.21.3\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/pytorch_model.bin\n","All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n","\n","All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at /content/drive/My Drive/Supernova-NLP/intent classification/intent classification.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n","Didn't find file /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/added_tokens.json. We won't load it.\n","loading file /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/sentencepiece.bpe.model\n","loading file None\n","loading file /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/special_tokens_map.json\n","loading file /content/drive/My Drive/Supernova-NLP/intent classification/intent classification/tokenizer_config.json\n"]}]},{"cell_type":"code","source":["dataset['test'][540]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_7GnXyGkRXw","executionInfo":{"status":"ok","timestamp":1662454311896,"user_tz":-240,"elapsed":278,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"d1c23fde-7f0e-4e45-9971-d772d509fcb9"},"execution_count":105,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'sentence': 'მიმდინარე წლის პირველ კვარტალში ქვეყანაში პირდაპირი უცხოური ინვესტიციების 14 % (55.7 მილიონი დოლარი) მშენებლობის სექტორში განხორციელდა.',\n"," 'label': 2,\n"," 'idx': 2126}"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","metadata":{"id":"1FITVD00nIiZ"},"source":["Enter sentence here"]},{"cell_type":"code","metadata":{"id":"GoqWawpiJcK8","executionInfo":{"status":"ok","timestamp":1662454557971,"user_tz":-240,"elapsed":328,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["demo_sentence = \"6 სექტემებრის მონაცმებით 2514 ადმიანი დაინფიცირდა\""],"execution_count":131,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oIpirBCsrgUp"},"source":["Tokenize sentence and predict label with model"]},{"cell_type":"code","metadata":{"id":"RM3TQsy7N0kk","executionInfo":{"status":"ok","timestamp":1662454560643,"user_tz":-240,"elapsed":344,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}}},"source":["tokenized = tokenizer(demo_sentence, padding='max_length', truncation=True, max_length=max_length)\n","input_ids = torch.LongTensor([tokenized['input_ids']])\n","attention_mask = torch.FloatTensor([tokenized['attention_mask']])"],"execution_count":132,"outputs":[]},{"cell_type":"code","source":["input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NOuoTbAN9Wn","executionInfo":{"status":"ok","timestamp":1662449500305,"user_tz":-240,"elapsed":312,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"46977e59-2d25-4e09-edb0-ce7f7020ceee"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[     0,  11075, 109288,  36764, 105069,  61406, 144947,   1320,      6,\n","         105195,  11144, 230786,      2,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1]])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["attention_mask"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NeT5MbLDOCSu","executionInfo":{"status":"ok","timestamp":1662449505844,"user_tz":-240,"elapsed":259,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"c32e3cbd-28bc-4cde-e4ec-6416e7a99dae"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.]])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"H8tQ72bROFhl","executionInfo":{"status":"error","timestamp":1662449510758,"user_tz":-240,"elapsed":482,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"3cd0f99a-435d-466b-9a52-49a5731f09d9"},"source":["outputs = []\n","for i,j in input_ids,attention_mask:\n","\n","  label_idx = model.forward(i,j).logits.argmax()\n","  outputs.append(label_idx)"],"execution_count":33,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-6777d2216d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mlabel_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"]}]},{"cell_type":"code","source":["label_idx = model.forward(input_ids,attention_mask).logits.argmax()\n","label_idx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hj1gOCA0toPw","executionInfo":{"status":"ok","timestamp":1662454566393,"user_tz":-240,"elapsed":697,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"5b608b7b-cadd-4046-9914-2a140711de73"},"execution_count":133,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3)"]},"metadata":{},"execution_count":133}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mpHtDVPkmVM8","executionInfo":{"status":"ok","timestamp":1662389696216,"user_tz":-240,"elapsed":5,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"8762cb0f-3769-46d0-cbcc-94cdc7b0d7f3"},"source":["for i in \n","  label = classLabel.int2str([label_idx])\n","label"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['პოლიტიკა და ომი']"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["label = classLabel.int2str([label_idx])\n","label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6WJp-2IyuMTm","executionInfo":{"status":"ok","timestamp":1662454572166,"user_tz":-240,"elapsed":295,"user":{"displayName":"pulsar pulsar","userId":"10530749131366566433"}},"outputId":"3e6c5c94-52e1-4dd7-ff31-539d8f896299"},"execution_count":134,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['კოვიდ-19']"]},"metadata":{},"execution_count":134}]}]}